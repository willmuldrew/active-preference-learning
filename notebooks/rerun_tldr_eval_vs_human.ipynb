{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import json\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import wandb\n",
    "import datasets\n",
    "\n",
    "import direct.openai_ranking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook pulls up the eval data from a set of experiments, and re-runs eval, but using human\n",
    "# completions from the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/will/.cache/huggingface/datasets/CarperAI___parquet/CarperAI--openai_summarize_tldr-536d9955f5e6f921/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n"
     ]
    }
   ],
   "source": [
    "data = datasets.load_dataset(\"CarperAI/openai_summarize_tldr\", split=\"test\")\n",
    "human_response_lookup = {p.replace(\" \", \"\"): h for p, h in zip(data['prompt'], data['label'])}\n",
    "\n",
    "def get_eval_data():\n",
    "    dfs = []\n",
    "    for r in wandb.Api().runs(\"bbnn/wm-apl-tldr\"):\n",
    "        if \"tldr-exp5-final1\" in r.tags:\n",
    "            cfg = json.loads(r.json_config)\n",
    "            for f in r.files():\n",
    "                if re.match(r\"evaluation_m[0-9]+_post_training_T0\\.25\\.json\", f.name):\n",
    "                    print(\"loading\", f.name, \" from \", r.name)\n",
    "                    root = \"/tmp\"\n",
    "                    f.download(root, replace=True)\n",
    "                    path = f\"{root}/{f.name}\"\n",
    "                    with open(path) as fh:\n",
    "                        d = json.load(fh)\n",
    "                    df = pd.DataFrame(d)\n",
    "                    df[\"human_response\"] = df[\"prompts\"].apply(lambda p: human_response_lookup.get(p.replace(\" \", \"\")))\n",
    "                    df[\"completions\"] = df[\"completions\"].str.lstrip()\n",
    "                    df[\"vs_completions\"] = df[\"vs_completions\"].str.lstrip()\n",
    "                    df[\"acquire_pairs_function\"] = cfg[\"exp5\"][\"value\"][\"acquire_pairs_function\"]\n",
    "                    df[\"seed\"] = int(cfg[\"seed\"][\"value\"])\n",
    "                    df[\"m\"] = int(f.name.split(\"_\")[1][1:])\n",
    "                    df[\"run_name\"] = r.name\n",
    "                    dfs.append(df)\n",
    "\n",
    "    return pd.concat(dfs)\n",
    "\n",
    "def get_winrate_vs_human(df):\n",
    "    print(set(df[\"acquire_pairs_function\"]), set(df[\"m\"]))\n",
    "    # get_preference(prompt: str, completion_a: str, completion_b: str, task_name: str, model: str = \"gpt-3.5-turbo\", request_logger=None, oracle_temperature=0.05, provider=\"azure\")\n",
    "    win_count = 0\n",
    "    batch = [dict(prompt=p, completion_a=r_a, completion_b=r_b) for p, r_a, r_b in zip(list(df[\"prompts\"]), list(df[\"completions\"]), list(df[\"human_response\"]))]\n",
    "    resps = direct.openai_ranking.get_preference_batch(batch, model=\"gpt-4\", request_logger=None, num_threads=1, task_name=\"tldr\", provider=\"openai\")\n",
    "    for resp in resps:\n",
    "        if resp[\"preferred\"] == 0:\n",
    "            win_count += 1\n",
    "    return win_count / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading evaluation_m128_post_training_T0.25.json  from  bright-music-233\n",
      "loading evaluation_m256_post_training_T0.25.json  from  bright-music-233\n",
      "loading evaluation_m512_post_training_T0.25.json  from  bright-music-233\n",
      "loading evaluation_m768_post_training_T0.25.json  from  bright-music-233\n",
      "loading evaluation_m128_post_training_T0.25.json  from  drawn-wave-232\n",
      "loading evaluation_m256_post_training_T0.25.json  from  drawn-wave-232\n",
      "loading evaluation_m512_post_training_T0.25.json  from  drawn-wave-232\n",
      "loading evaluation_m768_post_training_T0.25.json  from  drawn-wave-232\n",
      "loading evaluation_m128_post_training_T0.25.json  from  iconic-salad-231\n",
      "loading evaluation_m256_post_training_T0.25.json  from  iconic-salad-231\n",
      "loading evaluation_m512_post_training_T0.25.json  from  iconic-salad-231\n",
      "loading evaluation_m768_post_training_T0.25.json  from  iconic-salad-231\n",
      "loading evaluation_m128_post_training_T0.25.json  from  quiet-dawn-224\n",
      "loading evaluation_m256_post_training_T0.25.json  from  quiet-dawn-224\n",
      "loading evaluation_m512_post_training_T0.25.json  from  quiet-dawn-224\n",
      "loading evaluation_m768_post_training_T0.25.json  from  quiet-dawn-224\n",
      "loading evaluation_m128_post_training_T0.25.json  from  peachy-jazz-223\n",
      "loading evaluation_m256_post_training_T0.25.json  from  peachy-jazz-223\n",
      "loading evaluation_m512_post_training_T0.25.json  from  peachy-jazz-223\n",
      "loading evaluation_m768_post_training_T0.25.json  from  peachy-jazz-223\n",
      "loading evaluation_m128_post_training_T0.25.json  from  rosy-flower-222\n",
      "loading evaluation_m256_post_training_T0.25.json  from  rosy-flower-222\n",
      "loading evaluation_m512_post_training_T0.25.json  from  rosy-flower-222\n",
      "loading evaluation_m768_post_training_T0.25.json  from  rosy-flower-222\n",
      "loading evaluation_m128_post_training_T0.25.json  from  cool-shadow-221\n",
      "loading evaluation_m256_post_training_T0.25.json  from  cool-shadow-221\n",
      "loading evaluation_m512_post_training_T0.25.json  from  cool-shadow-221\n",
      "loading evaluation_m768_post_training_T0.25.json  from  cool-shadow-221\n",
      "loading evaluation_m128_post_training_T0.25.json  from  astral-snowball-220\n",
      "loading evaluation_m256_post_training_T0.25.json  from  astral-snowball-220\n",
      "loading evaluation_m512_post_training_T0.25.json  from  astral-snowball-220\n",
      "loading evaluation_m768_post_training_T0.25.json  from  astral-snowball-220\n",
      "loading evaluation_m128_post_training_T0.25.json  from  true-jazz-219\n",
      "loading evaluation_m256_post_training_T0.25.json  from  true-jazz-219\n",
      "loading evaluation_m512_post_training_T0.25.json  from  true-jazz-219\n",
      "loading evaluation_m768_post_training_T0.25.json  from  true-jazz-219\n",
      "loading evaluation_m128_post_training_T0.25.json  from  volcanic-fire-218\n",
      "loading evaluation_m256_post_training_T0.25.json  from  volcanic-fire-218\n",
      "loading evaluation_m512_post_training_T0.25.json  from  volcanic-fire-218\n",
      "loading evaluation_m768_post_training_T0.25.json  from  volcanic-fire-218\n",
      "loading evaluation_m128_post_training_T0.25.json  from  honest-silence-217\n",
      "loading evaluation_m256_post_training_T0.25.json  from  honest-silence-217\n",
      "loading evaluation_m512_post_training_T0.25.json  from  honest-silence-217\n",
      "loading evaluation_m768_post_training_T0.25.json  from  honest-silence-217\n",
      "loading evaluation_m128_post_training_T0.25.json  from  rich-bush-216\n",
      "loading evaluation_m256_post_training_T0.25.json  from  rich-bush-216\n",
      "loading evaluation_m512_post_training_T0.25.json  from  rich-bush-216\n",
      "loading evaluation_m768_post_training_T0.25.json  from  rich-bush-216\n"
     ]
    }
   ],
   "source": [
    "df = get_eval_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "acquire_pairs_function  m    seed \n",
       "CERTAINTY               128  42       512\n",
       "                             29716    512\n",
       "                             41697    512\n",
       "                        256  42       512\n",
       "                             29716    512\n",
       "                             41697    512\n",
       "                        512  42       512\n",
       "                             29716    512\n",
       "                             41697    512\n",
       "                        768  42       512\n",
       "                             29716    512\n",
       "                             41697    512\n",
       "ENTROPY                 128  42       512\n",
       "                             29716    512\n",
       "                             41697    512\n",
       "                        256  42       512\n",
       "                             29716    512\n",
       "                             41697    512\n",
       "                        512  42       512\n",
       "                             29716    512\n",
       "                             41697    512\n",
       "                        768  42       512\n",
       "                             29716    512\n",
       "                             41697    512\n",
       "OFFLINE                 128  42       512\n",
       "                             29716    512\n",
       "                             41697    512\n",
       "                        256  42       512\n",
       "                             29716    512\n",
       "                             41697    512\n",
       "                        512  42       512\n",
       "                             29716    512\n",
       "                             41697    512\n",
       "                        768  42       512\n",
       "                             29716    512\n",
       "                             41697    512\n",
       "RANDOM                  128  42       512\n",
       "                             29716    512\n",
       "                             41697    512\n",
       "                        256  42       512\n",
       "                             29716    512\n",
       "                             41697    512\n",
       "                        512  42       512\n",
       "                             29716    512\n",
       "                             41697    512\n",
       "                        768  42       512\n",
       "                             29716    512\n",
       "                             41697    512\n",
       "Name: prompts, dtype: int64"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby([\"acquire_pairs_function\", \"m\", \"seed\"]).prompts.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "N=512\n",
    "rows=[]\n",
    "\n",
    "for acq in set(df[\"acquire_pairs_function\"]):\n",
    "    for m in set(df[\"m\"]):\n",
    "        for seed in set(df[\"seed\"]):\n",
    "            sub_df = df[(df[\"acquire_pairs_function\"] == acq) & (df[\"m\"] == m) & (df[\"seed\"] == seed)]\n",
    "            assert len(sub_df) == N\n",
    "            w = get_winrate_vs_human(sub_df)\n",
    "            rows.append([acq, m, seed, N, w])\n",
    "            print(rows[-1])\n",
    "\n",
    "results_df3 = pd.DataFrame(rows, columns=[\"acq\", \"m\", \"seed\", \"N\", \"winrate\"])\n",
    "\n",
    "# A very expensive dataframe: :)\n",
    "results_df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results_df3.to_csv(\"data/tldr_winrate_vs_human.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
